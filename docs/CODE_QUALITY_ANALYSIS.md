# ðŸ” AnÃ¡lisis de Calidad de CÃ³digo - CompasScan

## ðŸ“Š Resumen Ejecutivo

**Archivo mÃ¡s grande:** `api/compas_core.py` (381 lÃ­neas)

**Problemas identificados:**
- âœ… **Bueno:** SeparaciÃ³n de responsabilidades en mÃ³dulos
- âš ï¸ **Mejorable:** Funciones largas con mÃºltiples responsabilidades
- âš ï¸ **Mejorable:** LÃ³gica compleja anidada
- âš ï¸ **Mejorable:** Queries hardcodeadas

---

## ðŸš¨ Problemas Detectados

### 1. `run_compas_scan()` - FunciÃ³n MonolÃ­tica

**UbicaciÃ³n:** `api/compas_core.py:282-381` (100 lÃ­neas)

**Problemas:**
- âŒ **MÃºltiples responsabilidades:** Orquesta todo el flujo de escaneo
- âŒ **LÃ³gica compleja anidada:** BÃºsqueda inicial, directa, clasificaciÃ³n todo mezclado
- âŒ **Queries hardcodeadas:** LÃ­nea 312-317 tiene queries estÃ¡ticas
- âŒ **DifÃ­cil de testear:** Muchas dependencias y flujos

**CÃ³digo actual:**
```python
async def run_compas_scan(user_input: str) -> ScanReport:
    # 1. Contexto
    # 2. Gemini
    # 3. Fallback web (bÃºsqueda inicial)
    # 4. BÃºsqueda directa
    # 5. ClasificaciÃ³n
    # 6. Resultados
```

**Refactor sugerido:**
```python
async def run_compas_scan(user_input: str) -> ScanReport:
    context = await get_brand_context(user_input)
    
    # Try AI first
    ai_result = await _try_ai_strategy(context)
    if ai_result:
        return ai_result
    
    # Fallback to web search
    return await _web_search_strategy(context)

async def _try_ai_strategy(context: BrandContext) -> Optional[ScanReport]:
    """Estrategia AI-First con Gemini."""
    
async def _web_search_strategy(context: BrandContext) -> ScanReport:
    """Estrategia de bÃºsqueda web con clasificaciÃ³n."""
    
async def _search_initial_candidates(context: BrandContext) -> list[CompetitorCandidate]:
    """BÃºsqueda inicial concurrente."""
    
async def _search_direct_competitors(names: set[str]) -> list[CompetitorCandidate]:
    """BÃºsqueda directa de competidores descubiertos."""
    
def _classify_all_candidates(candidates: list[CompetitorCandidate], context: BrandContext) -> ScanReport:
    """Clasifica todos los candidatos y retorna ScanReport."""
```

---

### 2. `classify_competitor()` - LÃ³gica Compleja

**UbicaciÃ³n:** `api/compas_core.py:226-279` (54 lÃ­neas)

**Problemas:**
- âš ï¸ **MÃºltiples fases mezcladas:** Descartar, analizar seÃ±ales, clasificar
- âš ï¸ **LÃ³gica anidada:** MÃºltiples if/elif anidados
- âš ï¸ **Hardcoded values:** `industry_terms` hardcodeado (lÃ­nea 261)

**Refactor sugerido:**
```python
def classify_competitor(candidate: CompetitorCandidate, brand_context: BrandContext) -> ClassificationResult:
    # Fase 1: Quick rejection
    if _should_reject_candidate(candidate):
        return ClassificationResult(valid=False, reason=_get_rejection_reason(candidate))
    
    # Fase 2: Signal analysis
    signals = _analyze_signals(candidate, brand_context)
    
    # Fase 3: Classification
    return _determine_classification(signals)

def _should_reject_candidate(candidate: CompetitorCandidate) -> bool:
    """Quick rejection checks."""
    
def _analyze_signals(candidate: CompetitorCandidate, context: BrandContext) -> list[str]:
    """Analyze all signals for classification."""
    
def _determine_classification(signals: list[str]) -> ClassificationResult:
    """Determine HDA/LDA based on signals."""
```

---

### 3. `get_brand_context()` - MÃºltiples Responsabilidades

**UbicaciÃ³n:** `api/compas_core.py:47-97` (51 lÃ­neas)

**Problemas:**
- âš ï¸ **Mezcla detecciÃ³n y extracciÃ³n:** URL detection + keyword extraction
- âš ï¸ **LÃ³gica de fallback mezclada:** BÃºsqueda de sitio oficial dentro de la funciÃ³n

**Refactor sugerido:**
```python
async def get_brand_context(user_input: str) -> BrandContext:
    cached = await cache.get_brand_context(user_input)
    if cached:
        return BrandContext(**cached)
    
    # Separate concerns
    url = await _detect_or_find_url(user_input)
    name = _extract_name_from_input(user_input, url)
    keywords = await _extract_keywords(url, name)
    
    context = BrandContext(name=name, url=url, keywords=keywords)
    await cache.set_brand_context(user_input, context.model_dump())
    return context

async def _detect_or_find_url(user_input: str) -> str:
    """Detect URL or search for official site."""
    
def _extract_name_from_input(user_input: str, url: str) -> str:
    """Extract brand name from input or URL."""
    
async def _extract_keywords(url: str, name: str) -> list[str]:
    """Extract keywords from website."""
```

---

### 4. Queries Hardcodeadas

**UbicaciÃ³n:** `api/compas_core.py:312-317`

**Problema:**
```python
queries = [
    f"related:{get_root_domain(context.url)}",
    f"similar brands to {context.name}",
    f"{context.name} competitors",
    f"streaming services like {context.name}",  # âš ï¸ Hardcoded "streaming"
]
```

**SoluciÃ³n:**
```python
def _generate_search_queries(context: BrandContext) -> list[str]:
    """Generate dynamic search queries based on brand context."""
    base_queries = [
        f"related:{get_root_domain(context.url)}",
        f"similar brands to {context.name}",
        f"{context.name} competitors",
    ]
    
    # Dynamic industry-specific query
    if context.keywords:
        industry = context.keywords[0] if context.keywords else "service"
        base_queries.append(f"{industry} services like {context.name}")
    
    return base_queries
```

---

## ðŸ“ˆ MÃ©tricas de Complejidad

| FunciÃ³n | LÃ­neas | Complejidad | Responsabilidades |
|---------|--------|-------------|-------------------|
| `run_compas_scan` | 100 | Alta | 5+ |
| `classify_competitor` | 54 | Media-Alta | 3 |
| `get_brand_context` | 51 | Media | 3 |
| `search_web` | 74 | Media | 2 |

**RecomendaciÃ³n:** Funciones deberÃ­an tener < 50 lÃ­neas y < 3 responsabilidades.

---

## âœ… Buenas PrÃ¡cticas Encontradas

1. âœ… **SeparaciÃ³n de mÃ³dulos:** Cada mÃ³dulo tiene responsabilidad clara
2. âœ… **Type hints:** Todo el cÃ³digo tiene type hints
3. âœ… **Pydantic models:** ValidaciÃ³n estricta de datos
4. âœ… **Async/await:** Uso correcto de async
5. âœ… **Error handling:** Try/catch apropiados
6. âœ… **Caching:** Implementado correctamente

---

## ðŸŽ¯ Plan de RefactorizaciÃ³n

### Prioridad Alta
1. **Refactorizar `run_compas_scan()`**
   - Dividir en funciones mÃ¡s pequeÃ±as
   - Separar estrategia AI de Web
   - Extraer queries a funciÃ³n helper

### Prioridad Media
2. **Refactorizar `classify_competitor()`**
   - Separar fases en funciones helper
   - Mover `industry_terms` a constants

3. **Refactorizar `get_brand_context()`**
   - Separar detecciÃ³n de URL
   - Separar extracciÃ³n de keywords

### Prioridad Baja
4. **Mejorar queries dinÃ¡micas**
   - Generar queries basadas en contexto
   - Eliminar hardcoding de "streaming"

---

## ðŸ“ Notas

- El cÃ³digo **NO es espaguetti crÃ­tico**, pero tiene oportunidades de mejora
- La estructura general es buena (mÃ³dulos separados)
- Las funciones largas son el principal problema
- La refactorizaciÃ³n mejorarÃ­a testabilidad y mantenibilidad

---

**Ãšltima actualizaciÃ³n:** $(date)

